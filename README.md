# ğŸ§  XGBoost vs Random Forest vs Gradient Boosting â€“ Regression Analysis

This repository provides a comparison of three powerful ensemble machine learning algorithms using the **California Housing dataset** for regression:

- ğŸ”¸ XGBoost Regressor  
- ğŸ”¸ Random Forest Regressor  
- ğŸ”¸ Gradient Boosting Regressor  

The goal is to predict housing prices and evaluate performance using **Mean Squared Error (MSE)**.

---

## ğŸ“ Files Included

| File Name                      | Description                                               |
|-------------------------------|-----------------------------------------------------------|
| `XgBoost_Algorithm.ipynb` | Main implementation for loading data, training models, and evaluating results |
| `README.md`                   | Project documentation                         |

---

## ğŸ“Š Dataset

**California Housing Dataset** from Scikit-learn  
â¡ï¸ Contains features such as average income, house age, population, etc.  
â¡ï¸ Target: Median house value in California districts.

---

## ğŸ›  Requirements

Install the dependencies via pip:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost
```
---
## ğŸš€ How to Run
1. Clone this repository:
```
git clone https://github.com/yourusername/xgboost-housing-analysis.git
cd xgboost-housing-analysis
```
2. Run the script:
```
python XG_Boost_Implementation.py
```
---
## ğŸ“Œ Key Steps
1. Data Loading
Load and split California Housing data using train_test_split.

2. Model Training
Train three models: XGBRegressor, RandomForestRegressor, and GradientBoostingRegressor.

3. Prediction & Evaluation
Predict on the test set and evaluate using mean_squared_error.

4. (Optional) Grid Search
Code for GridSearchCV is included but commented out.

---

## âœ… Results

| Model                   | Mean Squared Error |
|------------------------|--------------------|
| ğŸ§  XGBoost Regressor    | 0.2226             |
| ğŸŒ² Random Forest        | 0.2554             |
| ğŸ“ˆ Gradient Boosting    | 0.2940             |

âœ”ï¸ **XGBoost outperforms the others in terms of MSE.**

---

## ğŸš§ Future Improvements

- Enable and optimize using `GridSearchCV`
- Add more metrics: `RÂ² score`, `MAE`
- Add feature importance visualizations
- Integrate a simple web UI or API for predictions

---

## ğŸ“œ License

**MIT License**  
Feel free to use, modify, and distribute with attribution.

---

## ğŸ™ Acknowledgments

- [Scikit-learn](https://scikit-learn.org/)
- [XGBoost](https://xgboost.readthedocs.io/)

---

## ğŸ“¬ Contact

**Created by** [Your Name]  
ğŸ“§ Email: `rishitasarafp@gmail.com`  
ğŸŒ GitHub: Rishita-P-Saraf (https://github.com/Rishita-P-Saraf)
